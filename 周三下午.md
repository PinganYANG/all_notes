周三下午

#### 1. Binary classification

Pb: input $x\in \textbf{X}$,output $y\in \{0,1\}$

对于这样的问题，可以转化为一个利用$(x,y)$联合概率进行分类的问题【比如朴素贝叶斯分类器】



##### 1.1 线性

利用一些超平面可以线性分割，比如利用SVM



##### 1.2 非线性

通过将$w^Tx$映射为$w^T\phi(x)$来将非线性的自变量映射为线性，其中$\phi: \mathbb{X}\rightarrow\mathbb{R}^d$。比如在SVM中用一些高斯核函数



GLM
广义线性模型（Generalized Linear Models，简称GLM）是一种灵活的统计模型，用于描述变量之间的线性关系。GLM是普通线性回归模型的扩展，它允许响应变量（因变量）的分布遵循指数族分布，而不仅仅是正态分布。这使得GLM能够处理各种类型的数据和关系。

1. **随机分量**：描述响应变量 �*Y* 的概率分布。在GLM中，�*Y* 的分布属于指数族（如正态分布、二项分布、泊松分布等）。
2. **系统分量**：描述解释变量（自变量）的线性组合。这个部分类似于传统线性回归模型中的线性预测器，即 �=��*η*=*Xβ*，其中 �*X* 是解释变量的矩阵，�*β* 是系数向量。
3. **链接函数**：连接随机分量和系统分量。链接函数 �(⋅)*g*(⋅) 将响应变量的期望值 �*μ* 转化为线性预测器 �*η*，即 �(�)=�*g*(*μ*)=*η*。链接函数的选择取决于响应变量的分布类型和研究问题的具体需求。



#### 2. Logistic Regression for binary classification

Give a feature map $\phi: \mathbb{X}\rightarrow\mathbb{R}^d$，use the prediction $\theta \phi(x)\le 0$

感觉就是首先训练出参数$\theta$，然后将非线性的$x$利用$\phi(x)$映射到线性空间中，最后用$\theta\phi(x)$判断结果



##### 2.1 概率上讲

$$
P(y|x,\theta)=\frac{e^{\theta^T\phi(x)}}{1+e^{\theta^T\phi(x)}}
$$

这里用了一个sigmoid function:$\sigma(r)=\frac{e^r}{1+e^r}$

训练一个LR模型，需要用到的是Maximum Likelihood Estimation



let $(x_1,y_1),...,(x_n,y_n)$ be a training set, we got the:

$\phi(y,x)=\left\{ \begin{array}{ll} \phi(x)&y=1\\0&otherwise \end{array}\right.~~~P(y|\theta,x)=\frac{e^{\theta^T\phi(y,x)}}{\sum_ye^{\theta^T\phi(y,x)}}$
$$
Loss(\theta)=\prod_{i=1,...,n}P(y_i|\theta,x)=\prod_{i=1,...,n}\frac{e^{\theta^T\phi(y_i,x)}}{\sum_ye^{\theta^T\phi(y_i,x)}}
$$
这样对连乘可以取log：
$$
\rho(\theta)=log(Loss(\theta))=\sum_{i=1}^n(\theta^T\phi(y_i,x_i)-log(\sum e^{\theta^T\phi(y_i,x_i)}))
$$
所以相当于将向量$[z_i~~~\dots~~~z_k]\Rightarrow log(\sum_{i=1}^ne^{z_i})$，我们知道右侧的就是一个log-sum-up函数，是一个可优化的凸函数



因此可以用上Gradient Descent方法来优化取值

##### 2.2 如何确定$\phi$

- feature engineering
- 确定或计算features
- 选取一些恰当的核函数



#### 3. Multiclass Classification

共有$y=\{1,...,k\}$类

共有两种分类器：

- 一是分类是类一还是其他类
- 二是对类中每对分别进行binary class分类，然后投票

$P(y|\theta,x)=\frac{e^{\theta^T\phi(y,x)}}{\sum_ye^{\theta^T\phi(y,x)}}$

$z(x,\theta)=\sum_{y\in y(x)}e^{\theta^T\phi(y,x)}$

- 这其实是一个分割函数，分割函数用于确保概率分布总和（或积分）为1。

$A(x,\theta)=log(z(x,\theta))$

- 这其实是对数配分函数



##### 最大后验估计 Maximum à posteriori：

给定一个$x$和$\theta$，最有可能的$y$，即，$\underset{y\in y(x)}{max}~\theta^T\phi(x,y)$

在这种情况下，一旦scale大幅度上升：

- $z(x,\theta)$的计算很耗时
- 上面的max问题难以通过迭代来解决了



##### 多类别LR的最大似然估计MLE maximum likelihood estimation

对于$(x_i,y_i),...,(x_n,y_n)$
$$
Loss(\theta)=\prod_{i=1,...,n}P(y_i|\theta,x_i)=\prod_{i=1,...,n}\frac{e^{\theta^T\phi(y_i,x_i)}}{\sum_ye^{\theta^T\phi(y_i,x_i)}}
$$

$$
log(Loss(\theta))=\sum_{i=1}^n\theta^T\phi(y_i,x_i)-A(\theta)
$$

这个是concave的

这里的$A(\theta)$也是可以优化的



#### 4. Expotential familly on Y

the expotential familly on Y generate by the feature map $\phi: y\rightarrow \mathbb{R}^n$



##### 4.1 Finite Y

$P(y|\theta)=\frac{e^{\theta^T\phi(\theta)}}{z(\theta)},~~~z(\theta)=\sum_{y\in y}e^{\theta^T\phi(\theta)}$



当Y连续时的概率密度：

$P(y|\theta)=\frac{e^{\theta^T\phi(\theta)}}{z(\theta)}$

$z(\theta)=\int_ye^{\theta^T\phi(x)}dy$

##### 4.2 Exp. of distribution in exp. families

##### 4.3 Bernouilli

$B(p)=P(y|p)=\left\{ \begin{array}{ll} p&y=1\\1-p&other \end{array}\right.~~,~~y\in\{0,1\}$

$\phi(y)=y,~~P=\frac{e^\theta}{1+e^\theta},~~e^\theta=log(\frac{p}{1-p})$



##### 4.4 Gaussian

$f(y|\mu,\sigma)=\frac{1}{\sqrt{2n}}e^{\frac{(y-\mu)^2}{2\sigma^2}}$，$\phi(y)=\left[ \begin{array}{ll} y^2\\y \end{array}\right]$

##### 4.5 Exp

$f(y|\lambda)=\frac{1}{\lambda}e^{-\lambda y},~~\Phi(y)=y$

##### 4.6 Poisson



##### 4.7 Not in the familly

Cauchy $P(y)=\frac{1}{1+y^2}$



#### 5 Distribution on Paths

对于路径集$D=(V,A)$

有路径$P=\{v-d,p\}=\{y\in\{0,1\}\}=\sum y_a,~~y\in R^A,~~(y_p)_a=\left\{ \begin{array}{ll} 1&if~a\in P\\0&other \end{array}\right.$

对于一个类，$P(y_p|\theta)=e^{\theta^Ty_p},~~\phi(y)=y$ 这个就是说，在参数为$\theta$下，选择第p条路径的概率，这种情况下不需要非线性映射。

a同时考虑多个类时，$P(y|\theta)=\frac{e^{\theta^T\phi(\theta)}}{z(\theta)}$，$z(\theta)=\sum_{y\in y(x)}e^{\theta^Ty_p}$

##### MAP 最大后验估计

在所有可以选择的path y上，
$$
\underset{y\in y}{max}~\theta^Ty
$$
有$\theta^T y_p=\sum_{a\in P}\theta^Ty_a$，其中$a\in P$表示路径a在路径集P之中，小写的p表示选择的集合，大写的P是总的集，小写的a表示单个的路径
$$
\underset{y\in y}{max}~\theta^Ty=\underset{p\in P}{max}\sum_{a\in P}\theta^Ty_a
$$


##### 例：Bayesian Network

对于有向图而言，结果应该是连乘的

修车的例子
$$
P(y)=\prod_vP(y_v|y_{Parent(v)})=\sum_ve^{log(P(Y_a=y_v|Y_{parent(v)}=y_{parent(v)}))}\mathbb{1}(Y_{v}=y_v|Y_{Parent(v)}=y_{Parent(v)})
$$
就是说，在以v为父节点，以v为原因，产生的结果为y的概率乘积。

1是指示函数，表示：

- 在父节点取到v的前序结点$parent(v)$时，才会考虑这些节点。



#### Inference problem in an expotential familly



##### Inference problem or calculate the probability

对于给定的y，求他的概率$P(y|\theta)$

此时的期望是$\mathbb{E}(f(x)|\theta)=\sum_{y\in y}f(y)p(y|\theta)$



##### Conditional expectation 条件期望

给定一个标签，最后的期望

$\mathbb{E}(f(x)|\theta,y_k=\bar y_k)$



##### Potential Difficulty





##### 最大后验估计 MAP

$$
\underset{y}{max}P(y|\theta) 相当于求 \underset{y\in y}{max}~\theta^T\phi(y)
$$



#### log partition function 对数分割函数

Compute the gradient of the log partition func $A(\theta)$

$A(x,\theta)=log(z(x,\theta))=log(\sum_{y\in y(x)}e^{\theta^T\phi(y,x)})$

计算：
$$
\nabla_\theta A(\theta)=\frac{1}{z(\theta)}\sum_{y\in y}ye^{\theta^Ty}=\sum_{y\in y}y\frac{e^{\theta^Ty}}{z(\theta)}
$$
而后面的分数部分就是概率$P(y|\theta)$，因此就可以得出，在参数$\theta$条件下的总期望：
$$
\nabla_\theta A(\theta)=\mathbb{E}(Y|\theta)
$$




#### Writing the conditional likelihood

对于训练集$(x_1,y_1),...,(x_n,y_n)$，有：
$$
Loss(\theta)=\prod_{i=1}^n P(y_i|x_i,\theta)=\prod_{i=1}^n\frac{e^{\theta^T\phi(x_i,y_i)}}{z(x_i,\theta)}
$$

$$
log(Loss(\theta))=\sum_{i=1}^n\theta^T\phi(x_i,y_i)-A(x_i,\theta)
$$

这个是concave的，log+concave是一个凹的【？？？
$$
\nabla l(\theta)=\sum_{i=1}^n\phi(x_i,y_i)-\mathbb{E}(\phi(x_i,y_i)|\theta_i,x_i)
$$
$Q_i=Conv(\phi(x_i,y_i))=y\in y$

$Q$是一个凸包



在凸包中，梯度将解逐渐推向边界



#### Pipeline

$input \rightarrow 映射 \phi(y) \overset{\theta}{\rightarrow}\underset{y\in y}{max}~\theta^Ty(transfer~to~P(y|x,\theta))$

##### define the model

$P(y|\theta,x)=\frac{e^{\theta^T\phi(y,x)}}{\sum_ye^{\theta^T\phi(y,x)}}=\frac{e^{\theta^Ty}}{z(x,\theta)}$

##### transfer using a maximum likelihood approach

$max~\rho(w)=\sum_{i=1}^n\phi_w(x_i)^Ty_i-A(x_i,\phi_w(x_i)),~~\theta_i=\phi_w(x_i)$

其中$\theta_i=\phi_w(x_i)$的映射是通过NN完成的

use the Gradient Descent and autodifferenciation

$\nabla \rho(w)=\underset{w}{max}\sum_{i=1}^n y_i-\mathbb{E}(y|x_i,\theta_i)$

##### Predict using MAP

由model可以

- 计算$x\rightarrow \theta$的映射，一般用NN
- 利用MAP映射 $\underset{y\in y}{max}~\theta^Ty$



##### 可计算性 Tractability

tractability of MAP

对象：

$\underset{y\in y}{max} ~\theta^Ty$



Tractability of the log likelihood/ partition function

对象：

$z(\theta),~A(\theta)$



Tractability of its gradient/inference

对象：

$\mathbb{E}(y|\theta)$



#### Path problem

给定一个有向图$D=(V,A),~o\in V,d\in V$

这个最长路径问题有界的原因是可以利用topological order 的动态规划

给定一个exponential family，其中的MAP是一个最长路径问题，有：

定义$p\in P, y_p=[0~\dots~1~\dots~0]$其中$1$的位置是表示选择这个边。



$P(y|\theta)=\frac{e^{\theta^Ty}}{z(\theta)}$：这个方程是一个指数族分布的一般形式，其中 $ \theta $ 是参数向量，$ y $ 是观测数据，$ Z(\theta)$是归一化常数，确保概率之和为1。

$P(y_p|\theta)=\frac{e^{\sum_{a\in P}\theta_a}}{z(\theta)}$：这个方程看起来是针对特定路径$ P$的概率表达式。这里，你定义了$ y_p$ 作为一个向量，其中选择的边标记为1。这个表达式似乎是将指数族分布应用于图的路径选择，其中$\sum_{a \in P}\theta_a$表示沿路径$P$的边权重的总和。



那么这个模型的Pipeline是：
$$
input\rightarrow\phi_w\overset{(\theta_a)_{a\in A}}{\rightarrow}solve~ \underset{y\in y}{max}~\theta^Ty ~by~DP\overset{predict~y}{\rightarrow}
$$

##### MLE问题

写下一个MLE问题，在MLE问题下写出必须解决的：

- loglikelihood funciton
- inference problem



首先有$(x_i,p_i),...,(x_n,p_n)$

对应的标签$(x_i,y_i),...,(x_n,y_n)$

有：
$$
Loss(w)=\prod^n_{i=1}P(y_i|x_i,w)=\prod^n_{i=1}\frac{e^{\phi_w(x_i)^Ty_i}}{z(x_i,\phi(x_i))}
$$
$log$下的$Loss$
$$
\rho(w)=\sum_{i=1}^n(\phi_w(x_i)^Ty_i-A(x_i,\phi_w(x_i)))
$$


优化则要求的梯度，如下：

$\nabla_w \rho(w) = \sum^n_{i=1}J_w\theta_i(y_i-\mathbb{E}(y|x_i,\theta_i))$



##### Partition function

有概率$P(y|\theta)=\frac{\theta^Ty}{z(\theta)}$

其中$p\in P, y_p=[0~\dots~1~\dots~0]$其中$1$的位置是表示选择这个类。



计算：

对于$o\rightarrow d$路径

$z(\theta)=\sum_{p\in P_{od}}e^{\sum_{a\in P} \theta_a}$

利用DP计算最短路径

对于$o\rightarrow v$路径

$z_v(\theta) = \sum_{p\in P_{ov}}e^{\sum_{a\in P} \theta_a}=\sum_{a\in g^-(v),a=(u,v)}\sum_{Q\in P_{ou}}e^{\theta_a+\sum_{a\in Q}\theta_a}$

其中$g^-(v)$表示v的入点



其中动态规划方法:

$z_o(\theta)=1$，表示一定会从$o$出来

$z_v(\theta)=\sum_{a\in g^-(v)}e^{\theta_a}z_u(\theta)$，前一个状态决定下一个



推广为一般的形式：

$f_v(\theta)=\underset{a\in g^-(v)}{max}(\theta_a+f_u(a))$

$f_o(\theta)=0$







求个log likelihood gradient

$\nabla A(\theta)=\mathbb{E}(y|\theta)=\sum_{y\in y}yP(y|\theta)$

【可能是一个考试题

【说明这个问题也可以用动态规划的方法解决，如上个问题的思路





#### Fenchel Duality

首先我们可以算出一个从$x\overset{\nabla f}{\rightarrow}s$的梯度，那么从s到x的反向梯度呢？



定义：对于$f\R^n\rightarrow\R\cup+\infin$，如果：

- 是一个最小化的minimizer
- 并且不是处处都等于正无穷



那么其对偶为：

$f^*(s)=\underset{x}{sup}\{s^Tx-f(x)|x\in V\}$



性质：函数之和的对偶等于这些函数对偶的逐点最大值的下确界（infimal convolution）。



###### 例子：计算$\Omega(\mu)=\frac{1}{2}\Vert \mu\Vert_2^2$的对偶

首先根据凸函数对偶的性质1【见笔记 凸优化7】，由于$\Omega(\mu)$可微，则其对偶对应的$\theta$值一定对应着函数偏导等于0的点。

则有$\nabla \Omega(\mu)=\mu=0$

$\Omega^*(\theta)=\underset{\mu}{sup}\{\theta^T\mu-\Omega(\mu)|x\in V\}$

那么取sup时必然有$\theta=\mu$

那么回带后可以消掉sup和$\mu$，得到 $\Omega^*(\theta)=\frac{1}{2}\Vert \theta\Vert_2^2$



###### 例： 计算Fenchel 对偶

计算$\Omega(\mu)=\frac{1}{2}\Vert \mu\Vert^2_2+\mathbb{I}_c(\mu)$

其中$\mathbb{I}_C(\mu)$是指示函数，如果$\mu$在$C$中为0，否则为负无穷

首先我们想要取到sup时，必然不可能去负无穷，所以sup必然在$\mu \in\mathbb{C}$中取到

否则是负无穷。这时我们可以分类讨论。

首先一阶偏导为$\theta-\mu$，由于$\theta$定义域是整个实数空间，所以必然可以取到$\theta=\mu$。这样就和上一个问题相同。

有



###### 例： 计算Fenchel 对偶

计算$\Omega(\mu)=\sum_i\mu_ilog(\mu_i)+\mathbb{I}_c(\mu)$





#### Fenchel Young 不等式

$f(x)+f^*(s)\ge s^Tx$

证明：

$f^*(s)=\underset{x}{sup}\{s^Tx-f(x)|x\in V\}\ge s^Tx-f(x)$

$f^*(s)+f(x)\ge s^Tx$



##### 等号成立条件：

Fenchel-Young 不等式是凸分析中的一个核心结果，为凸函数及其共轭（Fenchel对偶）函数之间的关系提供了一个不等式。对于凸函数 $f $ 和它的共轭函数 $f^* $，Fenchel-Young 不等式表述为：

$
f(x) + f^*(y) \geq \langle x, y \rangle
$

这里的 $\langle x, y \rangle $ 表示 $x $ 和 $y $ 的点积。

Fenchel-Young 不等式取等号的条件是 $x $ 和 $y $ 满足次梯度的关系，即 $y $ 必须属于 $f $ 在 $x $ 处的次梯度 $\partial f(x) $，或等价地，$x $ 属于 $f^* $ 在 $y $ 处的次梯度 $\partial f^*(y) $。换句话说，取等号的条件是：

$
y \in \partial f(x) \quad \text{或} \quad x \in \partial f^*(y)
$

如果函数 **$f $ 是光滑的，即在其定义域内处处可微**，那么次梯度就简化为梯度，此时取等条件变为：

$
y = \nabla f(x) \quad \text{或} \quad x = \nabla f^*(y)
$

在更一般的情况下，如果 $f $ 或 $f^* $ 不是处处光滑的，那么我们需要使用次梯度的概念。次梯度是一个集合，包含了所有可能的 $y $ 使得对所有 $z $ 都有：

$
f(z) \geq f(x) + \langle y, z - x \rangle
$

**当 $f $ 是光滑且强凸的，那么 $f $ 和 $f^* $ 都是单调的，并且它们的梯度互为逆运算。**在这种情况下，不仅 Fenchel-Young 不等式对所有 $x, y $ 成立，并且对于每一对 $(x, y) $ 满足 $y = \nabla f(x) $ 或 $x = \nabla f^*(y) $，不等式取等号。



如果函数$f$是close concav且可微的，s是f在x处的梯度时$s=\nabla f(x)$，那么此时有 $f(x)+f^*(s)-x^Ts=0$。反过来也成立。

【close的条件：对于函数$f$和一个大于0的值$\alpha$，$\{x\in domf:f(x)\le\alpha\}$

![image-20231123150740959](C:\Users\cimum\AppData\Roaming\Typora\typora-user-images\image-20231123150740959.png)

【这是因为**根据对偶性质，梯度映射在原始空间和对偶空间之间是互逆的**

此时：

$s=\underset{x}{argmax}~x^Ts-f(s)$

$x=\underset{s}{argmax}~s^Tx-f(x)$







#### Bidual

如果一个函数$f$是close convex的，那么有$f^{**}=f$



对于y上的指数族expotential family，表示为$P(y|\theta)=\frac{e^{\theta^Ty}}{z(\theta)}$

对数分割函数为$A(\theta)=log(z(\theta))$，$\nabla A(\theta)=\mathbb{E}(Y|\theta)=\mu$

考虑到$A(\theta)$是对凸的，并且有$A^{**}(\theta)=A(\theta)$与上文的通过梯度和对偶的梯度等等的联系关系，就可以得到如下关系。

![image-20231123150754041](C:\Users\cimum\AppData\Roaming\Typora\typora-user-images\image-20231123150754041.png)



$A^*(\mu)=-H(P(.|\theta(\mu))$，$H(y)=-\sum_y qlog(q(y))$





已知

$A(\theta)=log(z(\theta))=log(\sum_{y\in y(x)}e^{\theta^Ty})$



$P(y|\theta)=\frac{e^{\theta^Ty}}{\sum_ye^{\theta^Ty}}$

$A^*(\mu)=\underset{\theta}{max} (\theta^T\mu-A(\theta))$

设$g(x)=\theta^T\mu-A(\theta)$

$\nabla g(\theta)=0=\mu-\mathbb{E}(y|\theta)$

回带，并在$A(\theta)$右乘上$\sum_yp(y|\theta)$，因为其就是概率之和，为1。得到：

$A^*(\mu)=\theta^T\sum_yyP(y|\theta)-log(\sum_ye^{\theta^Ty})[\sum_yp(y|\theta)]\\=\sum_yP(y|\theta)(\theta^Ty-log(\sum_ye^{\theta^Ty}))\\=\sum_yP(y|\theta)(log(e^{\theta^Ty})-log(\sum_ye^{\theta^Ty}))\\=\sum_yP(y|\theta)log(P(y|\theta))=-H(P(y|\theta))$

$A(\theta)=\underset{\mu}{max}(\theta^T\mu-A^*(\mu))=\underset{\mu}{max}(\theta^T\mu-H(P(y|\theta)))$



#### Loss based CO augmented Learning

##### Pipeline 

和别的Pipeline是一样的

##### Last layer： Linear Programming

还是和前面的一样，目的是
$$
max&\theta^T y\\&y \in\R^d
$$
它试图解决一个形式为 $\text{max} \ c^Ty$ 的问题，其中 $y$ 必须满足集合 $Y$ 的约束条件。这里也提到了扩展形式 $\text{max} \ c^T g(y) + h(y)$，这暗示了可能有一个非线性的组件 $g(y)$ 和一个正则化项或惩罚项 $h(y)$。



##### Loss Based learning

通过loss来学习，目标函数是最小化【原始-对偶】损失：
$$
\underset{w}{min}&\sum_{i=1}^n\rho(f\circ\phi_w(x),y)&having~(x_1,y_1),...,(x_n,y_n)\\
$$

#### Focus on the CO layer

##### Only focus on the CO layer

只需要专注于CO层

##### Primal dual loss

这指的是**原始-对偶损失**函数 $\ell(\bar{\theta}, \bar{y})$，它可能是用于解决原始问题和对偶问题的损失函数。在组合优化和机器学习的背景下，原始-对偶方法是一种强大的工具，尤其是在解决涉及硬约束的问题时。

目的是降低**原始-对偶**的损失

##### Goals: meaningful gradients losses

我们的目标是获得**有意义的梯度和损失**，这意味着我们希望能够通过反向传播有效地训练模型，并**确保损失函数足够光滑**，以便梯度下降或其他优化算法可以顺利地找到最优解。

##### piecewise constant on the normal fan

normal fan的边界上梯度是0，使得其会出现$\theta$改变但由于梯度为0，总值不变的不光滑的梯度情况。

![Uploaded image](https://files.oaiusercontent.com/file-rRI29eochVHgOZMjZ42yQ1wO?se=2023-11-25T21%3A51%3A56Z&sp=r&sv=2021-08-06&sr=b&rscc=max-age%3D3599%2C%20immutable&rscd=attachment%3B%20filename%3Dimage.png&sig=e2L%2Bd5GG/6Z4aaoycuhJr1eWz5pLhAIXZ7FAL4Tvma8%3D)

我们看到左边是一个凸多面体，代表线性规划问题的可行解空间，右边是这个多面体每个顶点对应的normal fan。Normal fan由从多面体顶点出发的射线组成，这些射线与多面体在该顶点处的边相切。换句话说，每个射线都是多面体某个面的法线。

Normal fan揭示了目标函数在该顶点附近的变化方式。在顶点处，目标函数的值不会随着沿法线方向的移动而改变，因为这些方向正好是目标函数值不变的方向。这意味着，如果我们在优化过程中到达了这样一个顶点，那么沿着这些方向的梯度（或导数）将为零，从而使得基于梯度的优化方法难以决定如何从这个顶点移动以改进目标函数的值。

Normal fan的内部，也就是每个扇区的内部，代表了在那个特定方向上目标函数将会增加或减少的区域。在凸优化问题中，这些扇区通常与目标函数沿某个方向的梯度有关。如果我们在多面体的某个顶点，沿着normal fan的内部方向移动，则目标函数的值将会变化。

在具体的线性规划问题中，如果目标函数是线性的，则沿着某个顶点的normal fan的边界方向移动，目标函数的值保持不变，因为这些方向与目标函数的等高线平行。相反，如果我们沿着扇区的内部方向移动，目标函数的值将会根据该方向上的梯度而增加或减少。

在normal fan的每个扇区中，存在一个与该扇区关联的约束条件。在扇区的内部方向上，目标函数的梯度指向约束条件放松的方向，意味着在那个方向上移动会远离当前顶点，并可能朝向另一个顶点或边界。这是因为每个扇区实际上表示了目标函数相对于多面体的一个特定面或边的优化方向。

当我们考虑非线性目标函数或者目标函数的非线性变换时，情况会更加复杂。在这些情况下，normal fan内部的梯度可能不是常数，而是会根据位置变化。这可以引导优化算法沿着梯度上升（或下降）方向移动，寻找局部或全局最优解。

总的来说，normal fan的边界代表了梯度为零的方向，而其内部代表了可以改进目标函数值的方向。在基于梯度的优化方法中，通常希望沿着normal fan内部的方向移动，以便找到目标函数的更高值（对于最大化问题）或更低值（对于最小化问题）。



#### Bregman 散度

对于一个凸函数 $f $，两个点 $x $ 和 $y $ 之间的Bregman散度 $D_f $ 定义为：

$D_f(x, y) = f(x) - f(y) - \langle \nabla f(y), x - y \rangle$

其中$\nabla f(y)$是函数$f$在$y$处的梯度。

##### 性质：

- **非负性**：对于任何 $x $和 $y$，$ D_f(x, y) \geq 0 $。等号成立当且仅当 $x = y$。

- 对于第一个参数是凸的：如果$f$是一个凸函数。这意味着对于所有的$x_1, x_2 \in \text{dom}(f)$和所有$\lambda \in [0,1]$，下面的不等式成立：

  $D_f(\lambda x_1 + (1-\lambda)x_2, y) \leq \lambda D_f(x_1, y) + (1-\lambda)D_f(x_2, y).$
  
- 在**对偶且$f$光滑强凸**【否则就没有**Fenchel-Young满足等式**且**梯度映射在原始空间和对偶空间之间是互逆**的这两个条件了】的条件下，有$x^*=\nabla f(x),y^*=\nabla f(y),D_f(x, y) = D_{f^*}(y^*,x^*)= f(x) + f^*(y^*) - \langle x, y^* \rangle$

  - 证明：由Fenchel对偶的性质，有$y^*=\nabla f(y)$，且有$f(y)=\langle y, y^* \rangle-f^*(y^*)$

  - 带入bregman散度，有：$D_f(x, y) = f(x) - \langle y, y^* \rangle+f^*(y^*) - \langle y^*, x - y \rangle=f(x)+f^*(y^*)-\langle x,y^*\rangle$

    


#### KL散度 Kullback Leibler Divergence 相对熵

有两个建立在$y$上的概率分布$P,Q$，则其KL散度为：
$$
KL(P|Q)=\sum_yP(y)log(\frac{P(y)}{Q(y)})=\mathbb{E}_{P}[log(\frac{P(y)}{Q(y)})]
$$
期望这里指的是变量log( )在概率分布P下的期望

例：证明$KL(P,Q)=D_{-H}(P,Q)$

右边是Bregman 散度

$H(P)=-\sum_yP(y)log(P(y))$

$f(P)=-H(P)$

$\nabla f(y) = [log(y)+1]^T$ 代表一个向量。通常这个梯度**不会保留这个+1项**，因此有下列证明：

$D_{-H}(P,Q)=\sum_{y\in y}P(y)log(P(y))-\sum_{y\in y}Q(y)log(Q(y))-(log(P(y))+1)^T(P(y)-Q(y))\\=\sum_{y\in y}P(y)log(P(y))-\sum_{y\in y}Q(y)log(Q(y))-\sum_{y\in y}P(y)log(P(y))+\sum_{y\in y}Q(y)log(Q(y))\\=\sum_yP(y)log(\frac{P(y)}{Q(y)})\\=KL(P,Q)$



##### 把最大似然估计 MLE看做最小化KL散度的问题

这张板书描述了最大似然估计（MLE）可以被视为最小化Kullback-Leibler (KL) 散度的过程。

在这个上下文中，$ p(y \mid \theta) $ 是参数 $ \theta $ 条件下的概率模型，而 $ \hat{p} $ 是观测数据的经验分布，这里表示为点 $ y_1, y_2, \ldots, y_n $。KL散度在这里用来度量经验分布 $ \hat{p} $ 和模型 $ p(y \mid \theta) $ 之间的不同。KL散度的一个常见形式是：

$
D_{KL}(\hat{p} \Vert p(y \mid \theta)) = \frac{1}{n} \sum_{i=1}^{n} \log \left( \frac{1/n}{p(y_i \mid \theta)} \right)
$

这里，$ 1/n $ 是每个观测值在经验分布中的概率。将其展开并忽略 $ \log(n) $（因为它是一个常数，不会影响最小化的参数 $ \theta $ 的位置），我们得到：

$
D_{KL}(\hat{p} \Vert p(y \mid \theta)) = -\frac{1}{n} \sum_{i=1}^{n} \log(p(y_i \mid \theta))
$

最小化KL散度相当于最大化似然函数 这里就是最大化log likelihood：

$
\max_{\theta} \sum_{i=1}^{n} \log(p(y_i \mid \theta))
$

这是因为最小化KL散度的负数等价于最大化似然函数。这里忽略了 $ 1/n $ 因子，因为它不会影响最大化过程。

因此，这张板书说明了在最大似然估计中，我们试图找到参数 $ \theta $ 的值，使得模型 $ p(y \mid \theta) $ 生成的分布尽可能接近观测数据的实际分布。通过这种方式，MLE可以被视为一种通过最小化数据和模型之间的KL散度来找到最佳模型参数的方法。





#### 重参数化技巧 Reparametrization Trick

首先我们有一个概率分布$P(y|\theta)$

对于这个概率分布，我们可以求得一个目标函数，就是说给定一个$\Theta$下的结果$f(y)$的期望：
$$
R(\Theta) = \mathbb{E}[f(y)|\theta] = \int f(y) p(y|\Theta) dy
$$
有目标函数，为了优化，则要求梯度。此时的梯度为：
$$
\nabla_\Theta R(\Theta) = \int f(y) \nabla_\Theta p(y|\Theta) dy
$$
这种情况下梯度很难求解，而且不再是$\nabla A(\theta)$这种期望的形式了，尤其是当$p $ 是由复杂模型如神经网络定义时。



重参数化技巧引入了一个变换$g(\Theta, \epsilon) $，它允许我们将$y $ 表达为$\Theta $ 的确定性函数和一个独立于$\Theta $ 的随机变量$\epsilon $ 的函数。这里$\epsilon $ 通常来自一个简单的分布，如标准正态分布。这样我们有$g(\Theta,\epsilon)\sim p(y|\Theta)$，相当于用$\epsilon$的随机性来代表$y$的随机性。

因此目标函数重参数化后变成：

$$
R(\Theta) = \int f(g(\Theta, \epsilon)) \bar p(\epsilon) d\epsilon
$$
其中$\bar p$表示一个新的概率分布。

这样，我们可以交换积分和微分的顺序，并且可以更容易地使用蒙特卡洛方法估计期望，进而计算总的梯度：

$$
\nabla_\Theta R(\Theta) = \int \nabla_\Theta f(g(\Theta, \epsilon)) \bar p(\epsilon) d\epsilon = \mathbb{E}_{\bar p(\epsilon)}[\nabla_\Theta f(g(\Theta, \epsilon))]
$$

##### 蒙特卡洛法：

蒙特卡洛方法是一种统计学上的随机抽样方法，用来估计不容易直接计算的数学表达式。在重参数化技巧的上下文中，蒙特卡洛方法被用来估计某个目标函数的梯度，这个目标函数包含了一个期望值。

考虑一个目标函数 $R(\Theta)$，它依赖于参数 $\Theta$，可以表示为一个期望：

$$
R(\Theta) = \mathbb{E}_{p(y|\Theta)}[f(y)],
$$

其中 $f(y)$ 是关于随机变量 $y$ 的函数，而 $p(y|\Theta)$ 是给定参数 $\Theta$ 下 $y$ 的概率分布。

通过引入一个独立的噪声变量 $\epsilon$，我们可以重写 $y$ 作为 $\Theta$ 和 $\epsilon$ 的函数，即 $y = g(\Theta, \epsilon)$。因此，目标函数的梯度可以改写为依赖于 $\epsilon$ 的期望：

$$
\nabla_\Theta R(\Theta) = \mathbb{E}_{p(\epsilon)}[\nabla_\Theta f(g(\Theta, \epsilon))].
$$

这个期望通常难以直接计算，所以我们使用蒙特卡洛方法来近似它。

蒙特卡洛方法的**具体步骤**包括：

1. 从独立噪声变量的分布 $p(\epsilon)$ 中抽取大量样本 $\epsilon_1, \epsilon_2, \ldots, \epsilon_N$。

2. 对于每个抽取的样本 $\epsilon_i$，计算 $g(\Theta, \epsilon_i)$ 和梯度 $\nabla_\Theta f(g(\Theta, \epsilon_i))$。

3. 计算梯度的蒙特卡洛近似，即所有计算出的梯度值的平均：

$$
\nabla_\Theta R(\Theta) \approx \frac{1}{N} \sum_{i=1}^{N} \nabla_\Theta f(g(\Theta, \epsilon_i)).
$$

使用这种方法，当样本数量 $N$ 足够大时，蒙特卡洛近似会根据大数定律逼近真实的期望值。这使得我们能够通过随机抽样方法估计那些复杂的，难以直接计算的期望值，这对于在神经网络如变分自编码器（VAEs）中进行参数优化特别有用。



#### 对数求导技巧 log derivative trick

这一技巧仍然是针对上一问题中难以求导的问题的一个解决思路。根据上一个trick，我们发现，如果我们把概率的梯度转化为另一个函数的梯度，并且保留概率项，就看把总梯度转化为一个期望。那么我们首先有：
$$
\nabla_\Theta R(\Theta) = \int f(y) \nabla_\Theta p(y|\Theta) dy=\int f(y) \frac{\nabla_\Theta p(y|\Theta)}{p(y|\Theta)}p(y|\Theta) dy=\int f(y) \nabla_\Theta log(p(y|\Theta))p(y|\Theta) dy
$$
使得:
$$
\nabla_{\Theta} R(\Theta) = \mathbb{E}_{p(y|\Theta)}[\nabla_{\Theta} \log p(y|\Theta) f(y)]
$$


对于一个指数族 expotential family：

$p(y|\Theta)=e^{\Theta^T\phi (y)-A(\Theta)}$

那么根据我们前面的知识，有$\nabla_{\Theta} \log p(y|\Theta) =\phi(y)-\mathbb{E}(\phi(y|\Theta))$

回带到总梯度中，有：
$$
\nabla_{\Theta} R(\Theta) =\mathbb{E}(f(y)[\phi(y)-\mathbb{E}(\phi(y|\Theta))]|\Theta)近似等价于计算cov(f(y),\phi(y)|\Theta)
$$
【最后的cov这里不一定是对的



考虑两种trick：

- 优先使用重参数reparametriization trick，他有更低的variance
- 注意估计协方差 covariance

#### 勒让德（Legendre）型函数及镜像映射（mirror maps）



##### 勒让德型函数的**性质**：

1. 定义域非空：$\text{dom}(\psi)$ 是非空的，这意味着存在至少一个点在 $\psi$ 的定义域内。

2. 在其定义域的内部可微：$\psi$ 在 $\text{int}(\text{dom}(\psi))$ 上可微分，即 $\psi$ 在其定义域内部的每一点都有一个明确的梯度。

3. 边界梯度无穷大：对于任何收敛到定义域边界的序列 $\mu_i$，梯度趋于无穷大，即 $\lim_{\mu_i \to \text{boundary}} \nabla \psi(\mu_i) = \infty$。

4. 严格凸性：$\psi$ 是严格凸的，这意味着其任意两点之间的线段上的任意点的函数值都小于这两点的函数值的线性插值。

满足以上四个条件的就可以称为勒让德（Legendre）型函数





##### 镜像映射 Mirror Maps

在这种情况下，这样的函数可以用来构建镜像映射，这是一种优化技术，特别是在对偶空间中进行优化时。镜像映射**利用一个凸函数来转换优化问题中的梯度**，使得原本可能很难处理的问题变得更容易优化。

图上展示了一个可能的 $\text{dom}(\psi)$，这看起来像是一个凸集。箭头表示梯度的方向，它们在接近边界时变得非常大，这与勒让德型函数的边界梯度无穷大的性质相符。

镜像映射在机器学习中的一些算法，比如镜像下降法（mirror descent）中非常有用，因为它们可以在参数空间中更有效地导航，特别是当参数空间受到某些约束或者当标准梯度下降法效率不高时。通过将参数空间映射到一个由函数 $\psi$ 定义的对偶空间，然后在对偶空间中执行优化步骤，最后将结果映射回原始空间，可以实现更加有效的优化过程。



这张板书似乎在描述



#### 非优化损失（Non-optimality loss）

这种损失函数的设计是为了量化预测解的非最优性，即模型预测的解与实际最优解之间的偏差。

##### 基本思想：

最小化真实解的非最优性作为预测问题的最优解。

用数学符号表示就是，我们有一个损失函数 $\ell(\hat{y}, y)$，其中 $\hat{y}$ 是模型的预测，$y$ 是真实的最优解。损失函数的目标是最小化预测和真实最优解之间的差异：
$$
\ell(\theta, \bar y) = \text{max} \ \theta^T y - max\ \theta^T \bar{y}
$$

理想情况下，如果预测是完美的，这个损失应该是零。



##### Why doesn't it work?

，暗示这种方式可能存在问题。一种可能的问题是，如果预测解 $\hat{y}$ 不在可行域内，或者损失函数不光滑（例如，在最优化问题的解是多面体顶点时），这可能会导致梯度计算不准确或不存在。

在机器学习中处理这类问题的一种方法是使用替代损失函数，它们在整个参数空间中都是光滑的，从而允许梯度下降等算法有效工作。另一种方法是使用次梯度或者镜像下降等能够处理非光滑函数的优化算法。



#### 正则化预测 Regularized prediction

首先是为了让预测不在边界产生，将结果“推入”内部之中。目的是帮助解决上一个非优化损失问题

设 $\Omega$ 是一个严格凸函数，用于正则化一个最大化问题。$C$是y的一个凸包。这里，$\hat{y}(\Theta)$ 表示给定参数 $\Theta$ 下的预测问题的最优解，即：
$$
\hat{y}(\Theta) = \underset{\mu \in C}{arg~max} f_0(\mu) \text{ with } f_0(\mu) = \langle \Theta | \mu \rangle - \Omega(\mu)
$$

其中，$C$ 是预测问题的可行域，$f_0(\mu)$ 是目标函数，由参数 $\Theta$ 与变量 $\mu$ 的内积减去**正则化项** $\Omega$ 组成。

 $I_C$是集合 $C$ 上的指示函数，后者对于 $\mu \in C$ 为零，否则为无穷大。 $I_C$使得所有的变量都控制在$C$之中，因为如果不在C之中，正无穷对于max问题是无意义的。因此我们也可以将原式表达为：
$$
max~f_0(\mu)=\underset{\mu\in C}{max}~\langle \Theta | \mu \rangle - \Omega(\mu) =\underset{\mu\in\R^d}{max}~\langle \Theta | \mu \rangle - (\Omega(\mu)+\mathbb{I}_C(\mu))\\\text{设}\Omega(\mu)+\mathbb{I}_C(\mu)=\Omega_C\\
\Rightarrow\Omega_c^*(\theta)
$$


对于 $C$ 是单纯形 $\Delta^d$ 的情况

##### sparse max $\Omega(\mu)=\frac{1}{2} \|\mu\|^2_2 + I_C(\mu)$

此时的原max问题变为：
$$
\langle \Theta | \mu \rangle-\frac{1}{2}\|\mu\|^2_2=-\frac{1}{2}\|\theta-\mu\|^2_2-\frac{1}{2}\|\theta\|^2_2
$$
此时：
$$
max&\langle \Theta | \mu \rangle-\frac{1}{2}\|\mu\|^2_2\Leftrightarrow &min&\frac{1}{2}\|\theta-\mu\|^2_2\\
$$
相当于尽量将polytope外的$\theta$向simplex的pareto front做的垂直投影。因为正则会使得问题变为sparse max，$\theta$不一定在端点或者边界上。因此这个投影是可行最优解。因为垂直于pareto front的是垂直于边界的，在这个方向上梯度为0，可以直接投影。



对于：

##### soft max$\Omega(\mu) = \sum_i \mu_i \log(\mu_i) + I_C(\mu)$

##### 

原问题相当于：
$$
max&\theta^T\mu-\sum_i \mu_i \log(\mu_i)\\s.t.&\sum\mu_i=1\\&\mu_i>0
$$

那么我们考虑KKT的互补松弛条件【14.4】，设等式约束的对偶变量为$\lambda_i$有：
$$
\nabla(\theta^T\mu-\sum_i \mu_i \log(\mu_i))+\lambda\nabla(1-\sum\mu_i)=0
$$
可以得出
$$
\mu_i\propto e^{\theta_i}
$$
如果算的话可以发现，$\mu_i = \frac{e^{\Theta_i}}{\sum_c e^{\Theta_c}}$是一个标准的**softmax**

由于我们的目标函数是一个关于$\mu$的argmax，因此可以说这个**softmax**结果是一个很具有现实意义的结果了



##### 关于指示函数：

在最优化问题中，当你有一个包含指示函数 $I_C(\mu)$ 的函数 $\Omega(\mu)$ 作为正则化项，并且这个指示函数定义在某个集合 $C$ 上时，指示函数的作用是确保优化问题的解 $\mu$ 位于集合 $C$ 内。具体来说，$I_C(\mu)$ 的值在 $\mu$ 属于集合 $C$ 时为 0，而当 $\mu$ 不属于集合 $C$ 时为无穷大。

因此，当指示函数 $I_C(\mu)$ 被包含在目标函数 $f_0(\mu)$ 中时，它限制了最大化过程仅在集合 $C$ 内的 $\mu$ 上进行。在这种情况下，函数 $f_0(\mu)$ 可以被写成如下形式：

$$
f_0(\mu) = \langle \Theta | \mu \rangle - \frac{1}{2} \|\mu\|^2_2 - I_C(\mu)
$$

由于指示函数 $I_C(\mu)$ 在集合 $C$ 之外的值为无穷大，最大化目标函数 $f_0(\mu)$ 的过程自然会忽略掉不在集合 $C$ 内的 $\mu$，因为这些 $\mu$ 会导致目标函数值变为负无穷大。换句话说，尽管 $\Omega(\mu)$ 包含指示函数，但在最大化过程中，只有当 $\mu \in C$ 时，$I_C(\mu)$ 才不会对目标函数值有贡献。这样，最大化过程实际上只考虑了集合 $C$ 内的 $\mu$，从而可以将指示函数从表达式中移除，因为在最优化过程中它的作用是隐式的。



##### 区分simplex上三种max：

###### max：

$$
max&\theta^Ty\\\hat y(\theta)=argmax~\theta^Ty=[0~~0~~...~~0~~1~~0~~...~~0]
$$

就会得到一个向量，1代表预测的类

###### sparse max

此时正则为$\Omega(\mu)=\frac{1}{2} \|\mu\|^2_2 $

此时细节参见上文

###### soft max

参见上文



##### polytope上的正则化预测

###### Regularized prediction

$$
max& \langle \Theta | \mu \rangle - \Omega(\mu)\\\mu\in C
$$



###### MAP

$$
max& \langle \Theta | \mu \rangle\\\mu\in C
$$



###### Sparse MAP

$$
max& \langle \Theta | \mu \rangle - \frac{1}{2}\Vert\mu\Vert^2\\
$$

就是说sparse MAP是regularized prediction的一个特例。最后的预测结果要向polytope的pareto front做垂直投影





#### Regularized Non-optimality

对一个Non-op问题加上正则化

一个Non-op问题：
$$
\ell(\theta, \bar y) = \text{max} \ \theta^T y - max\ \theta^T \bar{y}
$$
【分别】加上正则项
$$
\ell(\theta, \bar y) = \underset{\mu\in C}{max} \ \theta^Ty -\Omega(y)-( \ \theta^T \bar{y}-\Omega(\bar y))\\=\Omega^*(\theta)+\Omega(y)-\theta^Ty
$$


#### Fenchel Young losses

Fenchel Young 不等式：
$$
\Omega^*(\theta)+\Omega(y)-\theta^Ty\ge0
$$


Fenchel Young losses来自于Fenchel Young不等式的推导，
$$
\ell(\theta, y) =\Omega^*(\theta)+\Omega(y)-\theta^Ty
$$

###### 性质：

- **正性（Positivity）**：$\ell(\Theta, y) \geq 0$。这意味着损失函数的值总是非负的。

- **零损失（Zero）**：当 $\Theta$ 是 $y$ 的次梯度时，$\ell(\Theta, y) = 0$。这表示当**预测与真实值“对偶匹配”时，损失为零**。

- **凸性和次梯度（Convexity and subgradients）**：如果 $\Omega$ 是凸的，那么关于 $\Theta$ 的损失函数 $\ell(\Theta, y)$ 也是凸的。其次梯度是：

$$
\nabla_{\Theta} \ell(\Theta, y) = \nabla \Omega^*(\Theta) - y
$$

如果预测 $\hat{y}(\Theta)$ 是 $\Omega^*$ 在点 $\Theta$ 的梯度，那么上述次梯度可以简化为：

$$
\nabla_{\Theta} \ell(\Theta, y) = \hat{y}(\Theta) - y
$$

这是一个非常有用的性质，因为它说明了如何通过计算 $\Omega^*$ 的梯度来得到预测，并且这个梯度可以直接用于计算损失函数的梯度。



这样最小化这个损失，从Fenchel Young的角度来看，就是两个空间相互对偶，可以完美的相互转化，是一个完美的映射。而同理，将其转化为Loss后，Loss为0就是**预测与真实值“对偶匹配”时，损失为零**







#### 多面体上的扰动预测 Perturbed Prediction on a polytope

##### 定义：

函数 $F(\Theta)$ 定义为在多面体上的最大化问题的解的期望，其中解的形式是带有扰动项 $\zeta$ 的线性函数的最大化。这里，$\zeta$ 是来自某个分布 $D(0, I^d)$ 的随机变量，通常这个分布是以零为中心的高斯分布。
$$
F(\Theta) = \mathbb{E}[\text{max}_{y \in Y} \langle \Theta + \zeta | y \rangle]&\zeta\sim\N(0,I^d)\\
$$
对于$F$的计算：

- 首先是困难的
- 需要用蒙特卡洛法计算
  - $F(\Theta) \approx\frac{1}{n}\sum_{n=1}^n\underset{y\in y}{max}\langle \Theta + \zeta_i | y \rangle$



##### **随机梯度**：

$F(\Theta)$ 的梯度可以通过期望表示为：
$$
\nabla F(\Theta) = \mathbb{E}[\text{argmax}_{y \in Y} \langle \Theta + \zeta | y \rangle] = \hat{y}(\Theta)
$$

- 用蒙特卡洛法
- 随机梯度下降



##### 将扰动作为正则

设$\Omega=F^*(\Theta)$

那么对于Fenchel young loss，我们有
$$
\ell(\theta, y) =F(\theta)+\Omega(y)-\theta^Ty\\\nabla_\theta\ell(\theta, y)=\hat y(\theta)-y
$$




如果 $C$ 是一个多面体，并且 $R_C = \max_{y \in C} \|y\|$ 以及 $M = \mathbb{E}[\|\nabla_{\zeta}(Z)\|^2]^{1/2}$，则我们有以下性质：

- $F(\Theta)$ 是严格凸的，二次可微的，并且其梯度是 $R_C M$-Lipschitz 连续的。
- $\Omega(\mu)$ 是严格凸的，可微的，$\frac{1}{R_C M}$ 强凸的，并且是勒让德型。



这样的$\theta$空间和$y$空间是相互对偶的，可以通过$\theta$预测y，同时也可以用y预测$\theta$：

- $\hat{y}(\Theta) = \mathbb{E}[\text{argmax}_{y \in Y} \langle \Theta + \zeta | y \rangle] $用蒙特卡洛法计算
- $\hat\theta(y)=\underset{\theta\in\R^d}{argmin} \ell(\theta, y) $ 用Stockastic Gradient 计算



##### 概率分布：

在扰动预测的情况下，其概率分布和期望是：
$$
p(y | \Theta) = \mathbb{P}(y = \text{argmax}_{y \in Y} \langle \Theta + \zeta | y \rangle)
\\
\hat{y}(\Theta) = \mathbb{E}(y | \Theta)
$$

##### 利用log-derivative trick解决Regret loss ：

首先我们有
$$
\underset{\theta}{min}&\mathbb{R}(\theta)=\mathbb{E}(f(y)|\theta)\\
$$
根据上文，我们有:
$$
y^*(\theta)=\underset{y\in y}{argmax}~\theta^Ty
$$
表示最优解

加上扰动项：
$$
\eta=\theta+\zeta
$$
对于扰动项，我们有概率分布:
$$
p(\eta|\theta)=\frac{1}{\sqrt{\eta\pi}^d}e^{-\frac{(\eta-\theta)^2}{2}}
$$

$$
log(p(\eta|\theta))=constant-\frac{(\eta-\theta)^2}{2}\\\nabla log(p(\eta|\theta))=\zeta=\eta-\theta
$$

那么我们可以把regret loss 的表达式转化为：
$$
\mathbb{R}(\theta)=\mathbb{E}(f(y^*(\theta+\zeta)))\\\nabla\mathbb{R}(\theta)=cov(f(y^*(\eta))\nabla log(p(y|\theta)))=cov(f(y^*(\theta+\zeta)),\zeta)
$$
便于计算



#### Fenchel-Young 损失和Bregman 散度的联系



1. **勒让德型函数**：
   - 勒让德型函数$ \psi $ 满足$ \text{dom}(\psi^*) = \mathbb{R}^d $，这里$ \psi^* $ 是$ \psi $ 的共轭函数。
   - 集合$ C $ 包含在$ \psi $ 的定义域内，而$ \Omega $ 定义为$ \psi^* $ 加上$ C $ 上的指示函数$ I_C $。

2. **预测**：

   - $\hat{y}_\Omega(\theta) = \arg \max_{\mu \in \mathcal{C}} \left| \langle \theta | \mu \rangle - \psi_{\mu} \right| = \arg \min_{\mu \in \mathcal{C}} D_{\Omega} \left( \mu | \hat{y}_{\psi}(\theta) \right)$

   - $\hat{y}_\Omega(\Theta) $ 是在集合$ C $ 上使得$ \langle \Theta | \mu \rangle - \psi(\mu) $ 最大化的$ \mu $ 的值。

3. **Fenchel-Young 损失**：

   - Fenchel-Young 损失$ \ell_\Omega(\Theta, y) $ 表达为两个Bregman 散度之差：
     $ \ell_\Omega(\Theta, y) = D_\psi(y | \hat{y}_\psi(\Theta)) - D_\psi(\hat{y}_{\psi^*}(\Theta) | \hat{y}_\psi(\Theta)) $

4. **Bregman 散度不等式**：

   - $0\le B_{\psi}(y|\hat y_\Omega(\theta))\le\ell_\Omega(\theta,y)$

   - Bregman 散度$ B_\psi $ 总是非负的，并且当损失最小化时，Bregman 散度等于 Fenchel-Young 损失。





##### $\Omega=\psi$时

$\ell_\Omega(\theta,\bar y)=D_\Omega(\bar y,\tilde y(\theta))=D_{\Omega^*}(\theta,\tilde\theta(\bar y))\\\tilde y(\theta)=\nabla\Omega^*(\theta)\\\tilde\theta(\bar y)=\nabla\Omega(\bar y)$



#### 利用Fenchel Young Losses 的Supervised Learning

对于一个supervised Learning

目标函数为：
$$
min&\frac{1}{n}\sum_{i=1}^n\ell^{FYL}(\psi_w(x_i),\bar y_i)\\
$$
其中：$\psi_w(x_i)=\theta_i$

利用Stocastic Gradient计算

- $\nabla \ell^{FYL}(\theta,\bar y)=y-\hat y(\theta)$
- 自动求导



#### 概率方法进行Regret based Learning

$$
\underset{w}{min}&\frac{1}{n}\sum_{i=1}^n\mathbb{E}(f(y_i,x_i)|\psi_w(x_i))\\
$$

利用对数技巧计算





